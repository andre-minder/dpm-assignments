---
title: "Evaluations of positive and negative stimuli using the Affective Misattribution Procedure (AMP) and self-reports"
subtitle: "Data processing"
author: "Template: Ian Hussey; content: Andr√© Minder"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r, include=FALSE}

knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

```

# Dependencies

```{r}

library(tidyverse)
library(janitor) # for clean_names()
library(stringr)

```

# Get data

```{r}

# demographics
data_demographics_raw <- read_csv("../data/raw/data_demographics_raw.csv") |>
  janitor::clean_names()

# data_demographics_raw_messy <- read_csv("../../../data/AMP study/raw/data_demographics_raw_messy.csv", skip = 2) |>
#   janitor::clean_names()

# self report measure
data_selfreport_raw <- read_csv("../data/raw/data_selfreport_raw.csv") |>
  janitor::clean_names()

# affect attribution procedure
data_amp_raw <- read_csv("../data/raw/data_amp_raw.csv") |>
  janitor::clean_names()

```

# Demographics

```{r}

dat_age_gender <- data_demographics_raw |>
  select(subject, date, time, trialcode, response) |>
  pivot_wider(names_from = trialcode,
              values_from = response) |>
  mutate(gender = tolower(gender),
         gender = stringr::str_remove_all(gender, regex("\\W+")), # regex is both very useful and awful to write
         gender = case_when(gender == "female" ~ gender,
                            gender == "male" ~ gender,
                            gender == "nonbinary" ~ gender,
                            gender == "woman" ~ "female",
                            gender == "man" ~ "male",
                            TRUE ~ "other/missing/error"),
         age = case_when(str_detect(age, "^[0-9]+$") ~ age, # if the value is only numbers, keep it. 
                         TRUE ~ "other/missing/error")) 

```

# Exclusions / data quality

## AMP
Assignment question: How do we know the right number of trials?

A first thing to inspect is the number of trials for each subject. If we skim through the list quickly, we see  
that most participants went through 82 trials, consisting of 10 practice trials (5 negative, 5 positive) and 72 
test trials (36 positive and 36 negative primes). We can then use this df to test hypotheses about the "normal" 
number of trials.

```{r}


data_amp_trials <- data_amp_raw |> 
  group_by(subject) |> 
  count(trialcode) |> 
  pivot_wider(names_from = trialcode, values_from = n) |> 
  select(subject, instructions, ends_with("practice"), everything()) |> 
  mutate(all_practice_trials = prime_negative_practice + prime_positive_practice,
         all_test_trials = prime_negative + prime_positive)

```
We can get a good first impression of the trial numbers through visualization (however, this will not show us the  NA values). Both graphs imply that the mode of the distribution might be an appropriate measure of the regular  
number of trials. These visualizations also suggest that there are a couple of participants who deviate from this  regular number.

```{r}

# Histogram for all test trials
data_amp_trials |> 
  ggplot(aes(x=all_test_trials)) +
  geom_histogram() +
  theme_classic()

# Histogram for all practice trials
data_amp_trials |> 
  ggplot(aes(x=all_practice_trials)) +
  geom_histogram() +
  theme_classic()

```

We can then use the filter function to get some details about these deviations. Looking at these might help us 
finding out, why they deviate.

Check who deviates from the regular test trial number
```{r}
data_amp_trials |> 
  filter(all_test_trials != 72 | is.na(all_test_trials))

```

Check who deviates from the regular practice trial number
```{r}

data_amp_trials |> 
  filter(all_practice_trials != 10 | is.na(all_practice_trials))

```

Check who deviates from the regular condition pattern in the test trials
```{r}

data_amp_trials |> 
  filter(prime_negative != prime_positive)

```

Check who deviates from the regular condition pattern in the practice trials
```{r}

data_amp_trials |> 
  filter(prime_negative_practice != prime_positive_practice)

```

We can then use the gathered information to decide on what the number of "normal" trials is. One simple approach  would be to exclude everyone who deviates from the regular pattern. This might be a justifiable solution 
in our case, since the deviations are quite large and explainable (e.g. quitting the experiment in the beginning  or going through it twice). However, depending on our study design and our analyses, this might not be the 
right course of action. For example, excluding missing cases might distort the analyses (e.g. in large 
longitudinal designs, in which we often fail to measure everyone and everything) and lower the power of 
the analysis. In these cases, it might be more appropriate to not exclude these cases, but rather use methods 
that deal with these problems (e.g. multiple imputation or HLM).

```{r}

# Implementing the criteria and generating a df with an exclusion category
data_amp_trials_exclusions <- data_amp_trials |> 
  mutate(AMP_trials_exclusion = case_when(prime_negative != 36 ~ "exclude",
                                         prime_positive != 36 ~ "exclude",
                                         prime_negative_practice != 5 ~ "exclude",
                                         prime_positive_practice != 5 ~ "exclude",
                                         !is.na(instructions) ~ "exclude",
                                         TRUE ~ "include")) |> 
  select(subject, all_practice_trials, all_test_trials, AMP_trials_exclusion)

```


AMP Performance

```{r}

# Extracting the necessary information with the number of trials.
data_amp_performance_criteria <- data_amp_raw |> 
  filter(blockcode != "practice", 
         trialcode != "instructions") |> 
  mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |> 
  group_by(subject) |> 
  summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
  mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))

```

Join both dfs
```{r}

data_amp_trials_performance_exclusions <- 
  full_join(data_amp_trials_exclusions, data_amp_performance_criteria, by = "subject")


```

# Self-reports

```{r}

# trial level data
data_selfreport_trial_level <- data_selfreport_raw |>
  select(subject, trialcode, response) |>
  filter(trialcode %in% c("like", "prefer", "positive")) |>
  rename(item = trialcode) |>
  filter(response != "Ctrl+'B'") |>
  mutate(response = as.numeric(response))

# mean scored
data_selfreport_mean_score <- data_selfreport_trial_level |>
  group_by(subject) |>
  summarize(mean_evaluation = mean(response, na.rm = TRUE))

# combined
data_selfreport_scored <- 
  full_join(data_selfreport_trial_level |>
              pivot_wider(names_from = "item",
                          values_from = "response"),
            data_selfreport_mean_score,
            by = "subject")

```

# Affect Misattribution Procedure

TODO extract evaluations on the AMP test blocks and convert to an overall bias score

```{r}


```

# Combine

```{r}

# combine all dfs created in the previous chunks
data_processed_temp <- dat_age_gender |>
  full_join(data_selfreport_scored, by = "subject") |> 
  full_join(data_amp_trials_performance_exclusions, by = "subject")

# flag all subjects with more than one row in the wide-format data. these should be excluded in the analysis.
# a more elaborate approach would be to track down the individual dupicate cases and determine which of the mulitiple cases should be retained. 
data_processed_duplicates <- data_processed_temp |>
  count(subject) |>
  mutate(exclude_duplicate_data = if_else(n > 1, "exclude", "include")) |>
  select(-n)

# join in the duplicates df
data_processed_before_exclusions <- data_processed_temp |>
  full_join(data_processed_duplicates, by = "subject")
  

```

# Define master exclusions

```{r}

# create a master exclude_participant variable
data_processed <- data_processed_before_exclusions |>
  mutate(exclude_participant = case_when(tolower(age) == "test" ~ "exclude",
                                         tolower(gender) == "test" ~ "exclude",
                                         is.na(mean_evaluation) ~ "exclude",
                                         # in this case we will exclude participants with missing demographics data or outcomes measures data. 
                                         # Note that "list-wise exclusions" like this aren't always justified, as missingness often isn't at random. 
                                         # How to treat missing data is a  whole area of work in itself, which we wont cover here.
                                         is.na(age) ~ "exclude", 
                                         is.na(gender) ~ "exclude",
                                         is.na(prefer) ~ "exclude",
                                         is.na(like) ~ "exclude",
                                         is.na(positive) ~ "exclude",
                                         AMP_trials_exclusion == "exclude" ~ "exclude",
                                         exclude_amp_performance == "exclude" ~ "exclude",
                                         exclude_duplicate_data == "exclude" ~ "exclude",
                                         TRUE ~ "include")) |> 
  select(-c("exclude_duplicate_data", "exclude_amp_performance", "AMP_trials_exclusion"))

```

# Write to disk

```{r}

# in case this dir doesn't exist, create it
dir.create("../data/processed/")

# save data to disk in that dir
write_csv(data_processed, "../data/processed/data_processed.csv")

```

# Session info

```{r}

sessionInfo()

```


