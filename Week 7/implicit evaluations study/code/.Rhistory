data_amp_trials <- data_amp_raw |>
group_by(subject) |>
count(trialcode) |>
pivot_wider(names_from = trialcode, values_from = n) |>
select(subject, instructions, ends_with("practice"), everything()) |>
mutate(all_practice_trials = prime_negative_practice + prime_positive_practice,
all_test_trials = prime_negative + prime_positive) |>
mutate(AMP_trials_exlusion = case_when(prime_negative != 36 ~ "exclude",
prime_positive != 36 ~ "exclude",
prime_negative_practice != 5 ~ "exclude",
prime_positive_practice != 5 ~ "exclude",
!is.na(instructions) ~ "exclude",
TRUE ~ "include"))
# We can use the df from above to find deviations, e.g. with the function filter
data_amp_trials |>
filter(all_test_trials != 72)
# We can use the df from above to find deviations, e.g. with the function filter
data_amp_trials |>
filter(all_test_trials != 72 | is.na(all_test_trials))
# We could also visualize some aspects of the data
data_amp_trials |>
ggplot(aes(x=all_test_trials)) +
geom_histogram()
# We could also visualize some aspects of the data
data_amp_trials |>
ggplot(aes(x=all_test_trials)) +
geom_histogram() |>
theme_classic()
# We could also visualize some aspects of the data
data_amp_trials |>
ggplot(aes(x=all_test_trials)) +
geom_histogram() +
theme_classic()
# We could also visualize some aspects of the data
data_amp_trials |>
ggplot(aes(x=all_test_trials)) +
geom_histogram() +
theme_classic()
# We can use the df from above to find deviations very quickly. We can get a good first impression trough
# visualization (However, this will not show us the NA values)
data_amp_trials |>
ggplot(aes(x=all_test_trials)) +
geom_histogram() +
theme_classic()
data_amp_trials |>
ggplot(aes(x=all_practice_trials)) +
geom_histogram() +
theme_classic()
# Scatterplot for the test trials (negative and positive primes)
ggplot(data_amp_trials, aes(x=prime_negative, y=prime_positive)) +
geom_point() +
geom_smooth(method=lm , color="red", se=FALSE) +
theme_classic()
# Scatterplot for the test trials (negative and positive primes)
ggplot(data_amp_trials, aes(x=prime_negative_practice, y=prime_positive_practice)) +
geom_point() +
geom_smooth(method=lm , color="red", se=FALSE) +
theme_classic()
data_amp_trials |>
filter(all_practice_trials != 10 | is.na(all_practice_trials))
View(data_amp_trials)
data_amp_trials |>
filter(negative_prime != positive_prime)
data_amp_trials |>
filter(prime_negative != prime_positive)
# Check who deviates from the regular condition pattern in the practice trials
data_amp_trials |>
filter(prime_negative_practice != prime_positive_practice)
data_amp_trials_exclusions <- data_amp_trials |>
mutate(AMP_trials_exlusion = case_when(prime_negative != 36 ~ "exclude",
prime_positive != 36 ~ "exclude",
prime_negative_practice != 5 ~ "exclude",
prime_positive_practice != 5 ~ "exclude",
!is.na(instructions) ~ "exclude",
TRUE ~ "include"))
data_amp_trials_exclusions <- data_amp_trials |>
mutate(AMP_trials_exlusion = case_when(prime_negative != 36 ~ "exclude",
prime_positive != 36 ~ "exclude",
prime_negative_practice != 5 ~ "exclude",
prime_positive_practice != 5 ~ "exclude",
!is.na(instructions) ~ "exclude",
TRUE ~ "include")) |>
select(instructions, all_practice_trials, all_test_trials)
data_amp_trials_exclusions <- data_amp_trials |>
mutate(AMP_trials_exlusion = case_when(prime_negative != 36 ~ "exclude",
prime_positive != 36 ~ "exclude",
prime_negative_practice != 5 ~ "exclude",
prime_positive_practice != 5 ~ "exclude",
!is.na(instructions) ~ "exclude",
TRUE ~ "include")) |>
select(subject, instructions, all_practice_trials, all_test_trials)
View(data_amp_trials_exclusions)
# Extracting the necessary information with the number of trials.
data_amp_performance_criteria <- data_amp_raw |>
filter(blockcode != "practice",
trialcode != "instructions") |>
mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |>
group_by(subject) |>
summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))
data_amp_trials_performance_exclusions <-
full_join(data_amp_trials_exclusions, data_amp_performance_criteria, by = "subject")
View(data_amp_trials_performance_exclusions)
data_amp_trials_exclusions <- data_amp_trials |>
mutate(AMP_trials_exlusion = case_when(prime_negative != 36 ~ "exclude",
prime_positive != 36 ~ "exclude",
prime_negative_practice != 5 ~ "exclude",
prime_positive_practice != 5 ~ "exclude",
!is.na(instructions) ~ "exclude",
TRUE ~ "include")) |>
select(subject, instructions, all_practice_trials, all_test_trials, AMP_trials_exlusion)
# Extracting the necessary information with the number of trials.
data_amp_performance_criteria <- data_amp_raw |>
filter(blockcode != "practice",
trialcode != "instructions") |>
mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |>
group_by(subject) |>
summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))
data_amp_trials_performance_exclusions <-
full_join(data_amp_trials_exclusions, data_amp_performance_criteria, by = "subject")
View(data_amp_trials_performance_exclusions)
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(tidyverse)
library(janitor) # for clean_names()
library(stringr)
# demographics
data_demographics_raw <- read_csv("../data/raw/data_demographics_raw.csv") |>
janitor::clean_names()
# data_demographics_raw_messy <- read_csv("../../../data/AMP study/raw/data_demographics_raw_messy.csv", skip = 2) |>
#   janitor::clean_names()
# self report measure
data_selfreport_raw <- read_csv("../data/raw/data_selfreport_raw.csv") |>
janitor::clean_names()
# affect attribution procedure
data_amp_raw <- read_csv("../data/raw/data_amp_raw.csv") |>
janitor::clean_names()
dat_age_gender <- data_demographics_raw |>
select(subject, date, time, trialcode, response) |>
pivot_wider(names_from = trialcode,
values_from = response) |>
mutate(gender = tolower(gender),
gender = stringr::str_remove_all(gender, regex("\\W+")), # regex is both very useful and awful to write
gender = case_when(gender == "female" ~ gender,
gender == "male" ~ gender,
gender == "nonbinary" ~ gender,
gender == "woman" ~ "female",
gender == "man" ~ "male",
TRUE ~ "other/missing/error"),
age = case_when(str_detect(age, "^[0-9]+$") ~ age, # if the value is only numbers, keep it.
TRUE ~ "other/missing/error"))
# Assignment question: How do we know the right number of trials?
# A first thing to inspect is the number of trials for each subject. If we skim through the list quickly, we see
# that most participants went through 82 trials, consisting of 10 practice trials (5 negative, 5 positive) and 72
# test trials (36 positive and 36 negative primes). We can then use this df to test hypotheses about the "normal"
# number of trials.
data_amp_trials <- data_amp_raw |>
group_by(subject) |>
count(trialcode) |>
pivot_wider(names_from = trialcode, values_from = n) |>
select(subject, instructions, ends_with("practice"), everything()) |>
mutate(all_practice_trials = prime_negative_practice + prime_positive_practice,
all_test_trials = prime_negative + prime_positive)
# We can get a good first impression of the trial numbers through visualization (however, this will not show us the # NA values). Both graphs imply that the mode of the distribution might be appropriate as the regular number of
# trials. These visualizations also suggest that there are a couple of participants who deviate from this regular
# number.
# Histogram for all test trials
data_amp_trials |>
ggplot(aes(x=all_test_trials)) +
geom_histogram() +
theme_classic()
# Histogram for all practice trials
data_amp_trials |>
ggplot(aes(x=all_practice_trials)) +
geom_histogram() +
theme_classic()
# We can then use the filter function to get some details about these deviations. Looking at these might help us
# finding out, why they deviate.
# Check who deviates from the regular test trial number
data_amp_trials |>
filter(all_test_trials != 72 | is.na(all_test_trials))
# Check who deviates from the regular practice trial number
data_amp_trials |>
filter(all_practice_trials != 10 | is.na(all_practice_trials))
# Check who deviates from the regular condition pattern in the test trials
data_amp_trials |>
filter(prime_negative != prime_positive)
# Check who deviates from the regular condition pattern in the practice trials
data_amp_trials |>
filter(prime_negative_practice != prime_positive_practice)
# We can then use the gathered information to decide on what the number of "normal" trials is. One simple approach # would be to exclude everyone who deviates from the regular pattern. This might be a justifiable solution
# in our case, since the deviations are quite large (e.g. quitting the experiment in the beginning or
# going through it twice). However, depending on our study design and our analyses, this might not be the
# right course of action. For example, excluding missing cases might distort the analyses (e.g. in large
# longitudinal designs, in which we often fail to measure everyone and everything) and lower the power of
# the analysis. In these cases, it might be more appropriate to not exclude these cases, but rather use methods
# that deal with these problems (e.g. multiple imputation or HLMs).
# Implementing the criteria and generating a df with an exclusion category
data_amp_trials_exclusions <- data_amp_trials |>
mutate(AMP_trials_exlusion = case_when(prime_negative != 36 ~ "exclude",
prime_positive != 36 ~ "exclude",
prime_negative_practice != 5 ~ "exclude",
prime_positive_practice != 5 ~ "exclude",
!is.na(instructions) ~ "exclude",
TRUE ~ "include")) |>
select(subject, instructions, all_practice_trials, all_test_trials, AMP_trials_exlusion)
# Extracting the necessary information with the number of trials.
data_amp_performance_criteria <- data_amp_raw |>
filter(blockcode != "practice",
trialcode != "instructions") |>
mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |>
group_by(subject) |>
summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))
# Join both dfs
data_amp_trials_performance_exclusions <-
full_join(data_amp_trials_exclusions, data_amp_performance_criteria, by = "subject")
# trial level data
data_selfreport_trial_level <- data_selfreport_raw |>
select(subject, trialcode, response) |>
filter(trialcode %in% c("like", "prefer", "positive")) |>
rename(item = trialcode) |>
filter(response != "Ctrl+'B'") |>
mutate(response = as.numeric(response))
# mean scored
data_selfreport_mean_score <- data_selfreport_trial_level |>
group_by(subject) |>
summarize(mean_evaluation = mean(response, na.rm = TRUE))
# combined
data_selfreport_scored <-
full_join(data_selfreport_trial_level |>
pivot_wider(names_from = "item",
values_from = "response"),
data_selfreport_mean_score,
by = "subject")
# combine all dfs created in the previous chunks
data_processed_temp <- dat_age_gender |>
full_join(data_selfreport_scored, by = "subject") |>
full_join(data_amp_trials_performance_exclusions, by = "subject")
# flag all subjects with more than one row in the wide-format data. these should be excluded in the analysis.
# a more elaborate approach would be to track down the individual dupicate cases and determine which of the mulitiple cases should be retained.
data_processed_duplicates <- data_processed_temp |>
count(subject) |>
mutate(exclude_duplicate_data = if_else(n > 1, "exclude", "include")) |>
select(-n)
# join in the duplicates df
data_processed_before_exclusions <- data_processed_temp |>
full_join(data_processed_duplicates, by = "subject")
View(data_processed_before_exclusions)
# Implementing the criteria and generating a df with an exclusion category
data_amp_trials_exclusions <- data_amp_trials |>
mutate(AMP_trials_exclusion = case_when(prime_negative != 36 ~ "exclude",
prime_positive != 36 ~ "exclude",
prime_negative_practice != 5 ~ "exclude",
prime_positive_practice != 5 ~ "exclude",
!is.na(instructions) ~ "exclude",
TRUE ~ "include")) |>
select(subject, instructions, all_practice_trials, all_test_trials, AMP_trials_exclusion)
# Extracting the necessary information with the number of trials.
data_amp_performance_criteria <- data_amp_raw |>
filter(blockcode != "practice",
trialcode != "instructions") |>
mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |>
group_by(subject) |>
summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))
# Join both dfs
data_amp_trials_performance_exclusions <-
full_join(data_amp_trials_exclusions, data_amp_performance_criteria, by = "subject")
# Self-reports
```{r}
# trial level data
data_selfreport_trial_level <- data_selfreport_raw |>
select(subject, trialcode, response) |>
filter(trialcode %in% c("like", "prefer", "positive")) |>
rename(item = trialcode) |>
filter(response != "Ctrl+'B'") |>
mutate(response = as.numeric(response))
# mean scored
data_selfreport_mean_score <- data_selfreport_trial_level |>
group_by(subject) |>
summarize(mean_evaluation = mean(response, na.rm = TRUE))
# Affect Misattribution Procedure
TODO extract evaluations on the AMP test blocks and convert to an overall bias score
```{r}
# Combine
```{r}
# combine all dfs created in the previous chunks
data_processed_temp <- dat_age_gender |>
full_join(data_selfreport_scored, by = "subject") |>
full_join(data_amp_trials_performance_exclusions, by = "subject")
# flag all subjects with more than one row in the wide-format data. these should be excluded in the analysis.
# a more elaborate approach would be to track down the individual dupicate cases and determine which of the mulitiple cases should be retained.
data_processed_duplicates <- data_processed_temp |>
count(subject) |>
mutate(exclude_duplicate_data = if_else(n > 1, "exclude", "include")) |>
select(-n)
# join in the duplicates df
data_processed_before_exclusions <- data_processed_temp |>
full_join(data_processed_duplicates, by = "subject")
# create a master exclude_participant variable
data_processed <- data_processed_before_exclusions |>
mutate(exclude_participant = case_when(tolower(age) == "test" ~ "exclude",
tolower(gender) == "test" ~ "exclude",
is.na(mean_evaluation) ~ "exclude",
# in this case we will exclude participants with missing demographics data or outcomes measures data.
# Note that "list-wise exclusions" like this aren't always justified, as missingness often isn't at random.
# How to treat missing data is a  whole area of work in itself, which we wont cover here.
is.na(age) ~ "exclude",
is.na(gender) ~ "exclude",
is.na(prefer) ~ "exclude",
is.na(like) ~ "exclude",
is.na(positive) ~ "exclude",
AMP_trials_exclusion == "exclude" ~ "exclude",
exclude_amp_performance == "exclude" ~ "exclude",
exclude_duplicate_data == "exclude" ~ "exclude",
TRUE ~ "include")) |>
select(-c("exclude_duplicate_data", "exclude_amp_performance"))
View(data_processed)
# Implementing the criteria and generating a df with an exclusion category
data_amp_trials_exclusions <- data_amp_trials |>
mutate(AMP_trials_exclusion = case_when(prime_negative != 36 ~ "exclude",
prime_positive != 36 ~ "exclude",
prime_negative_practice != 5 ~ "exclude",
prime_positive_practice != 5 ~ "exclude",
!is.na(instructions) ~ "exclude",
TRUE ~ "include")) |>
select(subject, all_practice_trials, all_test_trials, AMP_trials_exclusion)
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(tidyverse)
library(janitor) # for clean_names()
library(stringr)
# demographics
data_demographics_raw <- read_csv("../data/raw/data_demographics_raw.csv") |>
janitor::clean_names()
# data_demographics_raw_messy <- read_csv("../../../data/AMP study/raw/data_demographics_raw_messy.csv", skip = 2) |>
#   janitor::clean_names()
# self report measure
data_selfreport_raw <- read_csv("../data/raw/data_selfreport_raw.csv") |>
janitor::clean_names()
# affect attribution procedure
data_amp_raw <- read_csv("../data/raw/data_amp_raw.csv") |>
janitor::clean_names()
dat_age_gender <- data_demographics_raw |>
select(subject, date, time, trialcode, response) |>
pivot_wider(names_from = trialcode,
values_from = response) |>
mutate(gender = tolower(gender),
gender = stringr::str_remove_all(gender, regex("\\W+")), # regex is both very useful and awful to write
gender = case_when(gender == "female" ~ gender,
gender == "male" ~ gender,
gender == "nonbinary" ~ gender,
gender == "woman" ~ "female",
gender == "man" ~ "male",
TRUE ~ "other/missing/error"),
age = case_when(str_detect(age, "^[0-9]+$") ~ age, # if the value is only numbers, keep it.
TRUE ~ "other/missing/error"))
# Assignment question: How do we know the right number of trials?
# A first thing to inspect is the number of trials for each subject. If we skim through the list quickly, we see
# that most participants went through 82 trials, consisting of 10 practice trials (5 negative, 5 positive) and 72
# test trials (36 positive and 36 negative primes). We can then use this df to test hypotheses about the "normal"
# number of trials.
data_amp_trials <- data_amp_raw |>
group_by(subject) |>
count(trialcode) |>
pivot_wider(names_from = trialcode, values_from = n) |>
select(subject, instructions, ends_with("practice"), everything()) |>
mutate(all_practice_trials = prime_negative_practice + prime_positive_practice,
all_test_trials = prime_negative + prime_positive)
# We can get a good first impression of the trial numbers through visualization (however, this will not show us the # NA values). Both graphs imply that the mode of the distribution might be appropriate as the regular number of
# trials. These visualizations also suggest that there are a couple of participants who deviate from this regular
# number.
# Histogram for all test trials
data_amp_trials |>
ggplot(aes(x=all_test_trials)) +
geom_histogram() +
theme_classic()
# Histogram for all practice trials
data_amp_trials |>
ggplot(aes(x=all_practice_trials)) +
geom_histogram() +
theme_classic()
# We can then use the filter function to get some details about these deviations. Looking at these might help us
# finding out, why they deviate.
# Check who deviates from the regular test trial number
data_amp_trials |>
filter(all_test_trials != 72 | is.na(all_test_trials))
# Check who deviates from the regular practice trial number
data_amp_trials |>
filter(all_practice_trials != 10 | is.na(all_practice_trials))
# Check who deviates from the regular condition pattern in the test trials
data_amp_trials |>
filter(prime_negative != prime_positive)
# Check who deviates from the regular condition pattern in the practice trials
data_amp_trials |>
filter(prime_negative_practice != prime_positive_practice)
# We can then use the gathered information to decide on what the number of "normal" trials is. One simple approach # would be to exclude everyone who deviates from the regular pattern. This might be a justifiable solution
# in our case, since the deviations are quite large (e.g. quitting the experiment in the beginning or
# going through it twice). However, depending on our study design and our analyses, this might not be the
# right course of action. For example, excluding missing cases might distort the analyses (e.g. in large
# longitudinal designs, in which we often fail to measure everyone and everything) and lower the power of
# the analysis. In these cases, it might be more appropriate to not exclude these cases, but rather use methods
# that deal with these problems (e.g. multiple imputation or HLMs).
# Implementing the criteria and generating a df with an exclusion category
data_amp_trials_exclusions <- data_amp_trials |>
mutate(AMP_trials_exclusion = case_when(prime_negative != 36 ~ "exclude",
prime_positive != 36 ~ "exclude",
prime_negative_practice != 5 ~ "exclude",
prime_positive_practice != 5 ~ "exclude",
!is.na(instructions) ~ "exclude",
TRUE ~ "include")) |>
select(subject, all_practice_trials, all_test_trials, AMP_trials_exclusion)
# Extracting the necessary information with the number of trials.
data_amp_performance_criteria <- data_amp_raw |>
filter(blockcode != "practice",
trialcode != "instructions") |>
mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |>
group_by(subject) |>
summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))
# Join both dfs
data_amp_trials_performance_exclusions <-
full_join(data_amp_trials_exclusions, data_amp_performance_criteria, by = "subject")
# trial level data
data_selfreport_trial_level <- data_selfreport_raw |>
select(subject, trialcode, response) |>
filter(trialcode %in% c("like", "prefer", "positive")) |>
rename(item = trialcode) |>
filter(response != "Ctrl+'B'") |>
mutate(response = as.numeric(response))
# mean scored
data_selfreport_mean_score <- data_selfreport_trial_level |>
group_by(subject) |>
summarize(mean_evaluation = mean(response, na.rm = TRUE))
# combined
data_selfreport_scored <-
full_join(data_selfreport_trial_level |>
pivot_wider(names_from = "item",
values_from = "response"),
data_selfreport_mean_score,
by = "subject")
# combine all dfs created in the previous chunks
data_processed_temp <- dat_age_gender |>
full_join(data_selfreport_scored, by = "subject") |>
full_join(data_amp_trials_performance_exclusions, by = "subject")
# flag all subjects with more than one row in the wide-format data. these should be excluded in the analysis.
# a more elaborate approach would be to track down the individual dupicate cases and determine which of the mulitiple cases should be retained.
data_processed_duplicates <- data_processed_temp |>
count(subject) |>
mutate(exclude_duplicate_data = if_else(n > 1, "exclude", "include")) |>
select(-n)
# join in the duplicates df
data_processed_before_exclusions <- data_processed_temp |>
full_join(data_processed_duplicates, by = "subject")
# create a master exclude_participant variable
data_processed <- data_processed_before_exclusions |>
mutate(exclude_participant = case_when(tolower(age) == "test" ~ "exclude",
tolower(gender) == "test" ~ "exclude",
is.na(mean_evaluation) ~ "exclude",
# in this case we will exclude participants with missing demographics data or outcomes measures data.
# Note that "list-wise exclusions" like this aren't always justified, as missingness often isn't at random.
# How to treat missing data is a  whole area of work in itself, which we wont cover here.
is.na(age) ~ "exclude",
is.na(gender) ~ "exclude",
is.na(prefer) ~ "exclude",
is.na(like) ~ "exclude",
is.na(positive) ~ "exclude",
AMP_trials_exclusion == "exclude" ~ "exclude",
exclude_amp_performance == "exclude" ~ "exclude",
exclude_duplicate_data == "exclude" ~ "exclude",
TRUE ~ "include")) |>
select(-c("exclude_duplicate_data", "exclude_amp_performance"))
View(data_processed)
# create a master exclude_participant variable
data_processed <- data_processed_before_exclusions |>
mutate(exclude_participant = case_when(tolower(age) == "test" ~ "exclude",
tolower(gender) == "test" ~ "exclude",
is.na(mean_evaluation) ~ "exclude",
# in this case we will exclude participants with missing demographics data or outcomes measures data.
# Note that "list-wise exclusions" like this aren't always justified, as missingness often isn't at random.
# How to treat missing data is a  whole area of work in itself, which we wont cover here.
is.na(age) ~ "exclude",
is.na(gender) ~ "exclude",
is.na(prefer) ~ "exclude",
is.na(like) ~ "exclude",
is.na(positive) ~ "exclude",
AMP_trials_exclusion == "exclude" ~ "exclude",
exclude_amp_performance == "exclude" ~ "exclude",
exclude_duplicate_data == "exclude" ~ "exclude",
TRUE ~ "include")) |>
select(-c("exclude_duplicate_data", "exclude_amp_performance", "AMP_trials_exclusion"))
View(data_processed)
# in case this dir doesn't exist, create it
dir.create("../../../data/AMP study/processed/")
# in case this dir doesn't exist, create it
dir.create("../data/processed/")
# save data to disk in that dir
write_csv(data_processed, "../data/processed/data_processed.csv")
library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
data_processed <- read_csv("../../../data/AMP study/processed/data_processed.csv")
data_processed <- read_csv("../data/processed/data_processed.csv")
data_processed <- read_csv("../data/processed/data_processed.csv")
View(data_processed)
data_processed_after_exclusions <- data_processed |>
filter(exclude_participant == "include")
View(data_processed_after_exclusions)
View(data_processed_after_exclusions)
