data_amp_score_congruent |>
filter(evaluative_response == 1 & trialcode_binary == 1 & prime_congruence == 0) |>
nrow() == 0
data_amp_score_congruent |>
filter(evaluative_response == 0 & trialcode_binary == 0 & prime_congruence == 0) |>
nrow() == 0
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(tidyverse)
library(janitor) # for clean_names()
library(stringr)
# demographics
data_demographics_raw <- read_csv("../data/raw/data_demographics_raw.csv") |>
janitor::clean_names()
# data_demographics_raw_messy <- read_csv("../data/raw/data_demographics_raw_messy.csv", skip = 2) |>
#   janitor::clean_names()
# self report measure
data_selfreport_raw <- read_csv("../data/raw/data_selfreport_raw.csv") |>
janitor::clean_names()
# affect attribution procedure
data_amp_raw <- read_csv("../data/raw/data_amp_raw.csv") |>
janitor::clean_names()
dat_age_gender <- data_demographics_raw |>
select(subject, date, time, trialcode, response) |>
pivot_wider(names_from = trialcode,
values_from = response) |>
mutate(gender = tolower(gender),
gender = stringr::str_remove_all(gender, regex("\\W+")), # regex is both very useful and awful to write
gender = case_when(gender == "female" ~ gender,
gender == "male" ~ gender,
gender == "nonbinary" ~ gender,
gender == "woman" ~ "female",
gender == "man" ~ "male",
TRUE ~ "other/missing/error"),
age = case_when(str_detect(age, "^[0-9]+$") ~ age, # if the value is only numbers, keep it.
TRUE ~ "other/missing/error"))
data_amp_performance_criteria <- data_amp_raw |>
filter(blockcode != "practice",
trialcode != "instructions") |>
mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |>
group_by(subject) |>
summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))
# determine modal number of trials
data_amp_completeness <- data_amp_raw |>
filter(blockcode != "practice",
trialcode != "instructions") |>
group_by(subject) |>
count() |>
ungroup() |>
mutate(exclude_amp_completeness = ifelse(n == 72, "include", "exclude")) |>
select(-n)
# data_amp_completeness |>
#   count(n)
# trial level data
data_selfreport_trial_level <- data_selfreport_raw |>
select(subject, trialcode, response) |>
filter(trialcode %in% c("like", "prefer", "positive")) |>
rename(item = trialcode) |>
filter(response != "Ctrl+'B'") |>
mutate(response = as.numeric(response))
# mean scored
data_selfreport_mean_score <- data_selfreport_trial_level |>
group_by(subject) |>
summarize(mean_evaluation = mean(response, na.rm = TRUE))
# combined
data_selfreport_scored <-
full_join(data_selfreport_trial_level |>
pivot_wider(names_from = "item",
values_from = "response"),
data_selfreport_mean_score,
by = "subject")
# Create column with congruence score
data_amp_score_congruent <- data_amp_raw |>
select(subject, evaluative_response = correct, trialcode, blockcode) |>
filter(blockcode != "practice",
trialcode != "instructions") |>
mutate(trialcode_binary = ifelse(trialcode == "prime_positive", 1, 0),
prime_congruence = ifelse(trialcode_binary == evaluative_response, 1, 0))
# Sanity check - Part I: Check with filter if there are any wrong calculations (e.g. congruence is represented as 1 even though response and trialcode are not congruent)
data_amp_score_congruent |>
filter(evaluative_response == 0 & trialcode_binary == 1 & prime_congruence == 1) |>
nrow() == 0
data_amp_score_congruent |>
filter(evaluative_response == 1 & trialcode_binary == 0 & prime_congruence == 1) |>
nrow() == 0
data_amp_score_congruent |>
filter(evaluative_response == 1 & trialcode_binary == 1 & prime_congruence == 0) |>
nrow() == 0
data_amp_score_congruent |>
filter(evaluative_response == 0 & trialcode_binary == 0 & prime_congruence == 0) |>
nrow() == 0
# Sanity check - Part I: Also check if congruence is always either 0 or 1
data_amp_score_congruent$prime_congruence %in% c(0,1) |>
all()
# Calculate AMP score
data_amp_score <- data_amp_score_congruent |>
group_by(subject) |>
summarize(AMP_score = mean(prime_congruence, na.rm = TRUE)) |>
select(subject, AMP_score)
# Sanity check - Part II: Check if score is still numeric. Also check if score lays between 0 and 1.
is.numeric(data_amp_score$AMP_score) & data_amp_score$AMP_score |> between(0, 1) |>
all()
# combine all dfs created in the previous chunks
data_processed_temp <- dat_age_gender |>
full_join(data_selfreport_scored, by = "subject") |>
full_join(data_amp_performance_criteria, by = "subject") |>
full_join(data_amp_completeness, by = "subject") |>
full_join(data_amp_score, by = "subject")
# flag all subjects with more than one row in the wide-format data. these should be excluded in the analysis.
# a more elaborate approach would be to track down the individual dupicate cases and determine which of the mulitiple cases should be retained.
data_processed_duplicates <- data_processed_temp |>
count(subject) |>
mutate(exclude_duplicate_data = if_else(n > 1, "exclude", "include")) |>
select(-n)
# join in the duplicates df
data_processed_before_exclusions <- data_processed_temp |>
full_join(data_processed_duplicates, by = "subject")
# create a master exclude_participant variable
data_processed <- data_processed_before_exclusions |>
mutate(exclude_participant = case_when(tolower(age) == "test" ~ "exclude",
tolower(gender) == "test" ~ "exclude",
is.na(mean_evaluation) ~ "exclude",
# in this case we will exclude participants with missing demographics data or outcomes measures data.
# Note that "list-wise exclusions" like this aren't always justified, as missingness often isn't at random.
# How to treat missing data is a  whole area of work in itself, which we wont cover here.
is.na(age) ~ "exclude",
is.na(gender) ~ "exclude",
exclude_amp_performance == "exclude" ~ "exclude",
exclude_duplicate_data == "exclude" ~ "exclude",
exclude_amp_completeness == "exclude" ~ "exclude",
is.na(AMP_score) ~ "exclude",
TRUE ~ "include"))
# in case this dir doesn't exist, create it
dir.create("../data/processed/")
# save data to disk in that dir
write_csv(data_processed, "../data/processed/data_processed.csv")
# set knit options
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
# disable scientific notation
options(scipen = 999)
library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
data_processed <- read_csv("../data/processed/data_processed.csv")
data_processed_after_exclusions <- data_processed |>
filter(exclude_participant == "include")
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |> # note that you can add header rows to tables like this. The "1" indicates the number of columns the header should span. The sum of these numbers must equal the number of columns or you'll get an error.
kable_classic(full_width = FALSE)
data_processed_after_exclusions |>
count(name = "n") |>
kable() |>
add_header_above(header = c("For analysis" = 1)) |>
kable_classic(full_width = FALSE)
data_processed_after_exclusions |>
mutate(age = as.numeric(age)) |>
summarise(Mean = mean(age, na.rm = TRUE),
SD = sd(age, na.rm = TRUE)) |>
mutate_all(.funs = janitor::round_half_up, digits = 1) |>
kable() |>
add_header_above(header = c("Age" = 2)) |>
kable_classic(full_width = FALSE)
data_processed_after_exclusions |>
rename(Gender = gender) |>
group_by(Gender) |>
summarise(n = n()) |>
mutate(Percent = paste0(round_half_up((n / sum(n)) * 100, 1), "%")) |>
mutate(Gender = stringr::str_to_sentence(Gender)) |> # Change the case of the Gender variable so that it prints nicely
kable() |>
kable_classic(full_width = FALSE)
# overall self-reported evaluations
dat_mean_ratings <- data_processed_after_exclusions |>
summarise(Mean = mean(mean_evaluation, na.rm = TRUE),
SD = sd(mean_evaluation, na.rm = TRUE)) |>
mutate(group = "Full sample")
# self-reported evaluations by gender category
dat_mean_ratings_by_gender <- data_processed_after_exclusions |>
group_by(group = gender) |>
summarise(Mean = mean(mean_evaluation, na.rm = TRUE),
SD = sd(mean_evaluation, na.rm = TRUE))
# combine both into one table
bind_rows(dat_mean_ratings,
dat_mean_ratings_by_gender) |>
select(Subset = group, Mean, SD) |> # select variables of interest, and rename one
mutate(Subset = stringr::str_to_sentence(Subset)) |> # Change the case of the Subset variable so that it prints nicely
mutate_if(is.numeric, round_half_up, digits = 2) |>
kable() |>
add_header_above(header = c(" " = 1, "Self-reported evaluations" = 2)) |>
kable_classic(full_width = FALSE)
data_processed_after_exclusions |>
filter(gender == "female")
# overall AMP score
dat_AMP_score <- data_processed_after_exclusions |>
summarise(Mean = mean(AMP_score, na.rm = TRUE),
SD = sd(AMP_score, na.rm = TRUE)) |>
mutate(group = "Full sample")
# self-reported evaluations by gender category
dat_AMP_score_by_gender <- data_processed_after_exclusions |>
group_by(group = gender) |>
summarise(Mean = mean(AMP_score, na.rm = TRUE),
SD = sd(AMP_score, na.rm = TRUE))
# combine both into one table
bind_rows(dat_AMP_score,
dat_AMP_score_by_gender) |>
select(Subset = group, Mean, SD) |> # select variables of interest, and rename one
mutate(Subset = stringr::str_to_sentence(Subset)) |> # Change the case of the Subset variable so that it prints nicely
mutate_if(is.numeric, round_half_up, digits = 2) |>
kable() |>
add_header_above(header = c(" " = 1, "Self-reported evaluations" = 2)) |>
kable_classic(full_width = FALSE)
data_processed_after_exclusions |>
filter(gender == "female")
lead(1:10)
lead(0:10)
lead(1:10)
lag(1:10)
# Introducing one NA value at the end of the vector
lead(1:10, n = 2)
# Introduce NA values to the column 'species' in the iris data set
iris_NAs <- iris |>
mutate(Species = lag(Species, n = 3))
View(iris_NAs)
# Introduce NA values to the column 'species' in the iris data set
iris_NAs <- iris |>
mutate(Species = lag(Species, n = 3, order_by = Species))
View(iris_NAs)
# Introduce NA values to the column 'species' in the iris data set
iris_NAs <- iris |>
mutate(Species = lag(Species, n = 3)) |>
arrange()
View(iris_NAs)
# Introduce NA values to the column 'species' in the iris data set
iris_NAs <- iris |>
mutate(Species = lag(Species, n = 3)) |>
arrange(Species)
View(iris_NAs)
lag(1:10)
# Introducing four NA values at the beginning of the vector
lag(1:10)
# Introducing four NA values at the beginning of the vector
lag(1:10, n = 4)
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(tidyverse)
library(janitor) # for clean_names()
library(stringr)
# demographics
data_demographics_raw <- read_csv("../data/raw/data_demographics_raw.csv") |>
janitor::clean_names()
# data_demographics_raw_messy <- read_csv("../data/raw/data_demographics_raw_messy.csv", skip = 2) |>
#   janitor::clean_names()
# self report measure
data_selfreport_raw <- read_csv("../data/raw/data_selfreport_raw.csv") |>
janitor::clean_names()
# affect attribution procedure
data_amp_raw <- read_csv("../data/raw/data_amp_raw.csv") |>
janitor::clean_names()
dat_age_gender <- data_demographics_raw |>
select(subject, date, time, trialcode, response) |>
pivot_wider(names_from = trialcode,
values_from = response) |>
mutate(gender = tolower(gender),
gender = stringr::str_remove_all(gender, regex("\\W+")), # regex is both very useful and awful to write
gender = case_when(gender == "female" ~ gender,
gender == "male" ~ gender,
gender == "nonbinary" ~ gender,
gender == "woman" ~ "female",
gender == "man" ~ "male",
TRUE ~ "other/missing/error"),
age = case_when(str_detect(age, "^[0-9]+$") ~ age, # if the value is only numbers, keep it.
TRUE ~ "other/missing/error"))
data_amp_performance_criteria <- data_amp_raw |>
filter(blockcode != "practice",
trialcode != "instructions") |>
mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |>
group_by(subject) |>
summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))
# determine modal number of trials
data_amp_completeness <- data_amp_raw |>
filter(blockcode != "practice",
trialcode != "instructions") |>
group_by(subject) |>
count() |>
ungroup() |>
mutate(exclude_amp_completeness = ifelse(n == 72, "include", "exclude")) |>
select(-n)
# data_amp_completeness |>
#   count(n)
# trial level data
data_selfreport_trial_level <- data_selfreport_raw |>
select(subject, trialcode, response) |>
filter(trialcode %in% c("like", "prefer", "positive")) |>
rename(item = trialcode) |>
filter(response != "Ctrl+'B'") |>
mutate(response = as.numeric(response))
# mean scored
data_selfreport_mean_score <- data_selfreport_trial_level |>
group_by(subject) |>
summarize(mean_evaluation = mean(response, na.rm = TRUE))
# combined
data_selfreport_scored <-
full_join(data_selfreport_trial_level |>
pivot_wider(names_from = "item",
values_from = "response"),
data_selfreport_mean_score,
by = "subject")
# Create column with congruence score
data_amp_score_congruent <- data_amp_raw |>
select(subject, evaluative_response = correct, trialcode, blockcode) |>
filter(blockcode != "practice",
trialcode != "instructions") |>
mutate(trialcode_binary = ifelse(trialcode == "prime_positive", 1, 0),
prime_congruence = ifelse(trialcode_binary == evaluative_response, 1, 0))
# Sanity check - Part I: Check with filter if there are any wrong calculations (e.g. congruence is represented as 1 even though response and trialcode are not congruent)
data_amp_score_congruent |>
filter(evaluative_response == 0 & trialcode_binary == 1 & prime_congruence == 1) |>
nrow() == 0
data_amp_score_congruent |>
filter(evaluative_response == 1 & trialcode_binary == 0 & prime_congruence == 1) |>
nrow() == 0
data_amp_score_congruent |>
filter(evaluative_response == 1 & trialcode_binary == 1 & prime_congruence == 0) |>
nrow() == 0
data_amp_score_congruent |>
filter(evaluative_response == 0 & trialcode_binary == 0 & prime_congruence == 0) |>
nrow() == 0
# Sanity check - Part I: Also check if congruence is always either 0 or 1
data_amp_score_congruent$prime_congruence %in% c(0,1) |>
all()
# Calculate AMP score
data_amp_score <- data_amp_score_congruent |>
group_by(subject) |>
summarize(AMP_score = mean(prime_congruence, na.rm = TRUE)) |>
select(subject, AMP_score)
# Sanity check - Part II: Check if score is still numeric. Also check if score lays between 0 and 1.
is.numeric(data_amp_score$AMP_score) & data_amp_score$AMP_score |> between(0, 1) |>
all()
# combine all dfs created in the previous chunks
data_processed_temp <- dat_age_gender |>
full_join(data_selfreport_scored, by = "subject") |>
full_join(data_amp_performance_criteria, by = "subject") |>
full_join(data_amp_completeness, by = "subject") |>
full_join(data_amp_score, by = "subject")
# flag all subjects with more than one row in the wide-format data. these should be excluded in the analysis.
# a more elaborate approach would be to track down the individual duplicate cases and determine which of the multiple cases should be retained.
data_processed_duplicates <- data_processed_temp |>
count(subject) |>
mutate(exclude_duplicate_data = if_else(n > 1, "exclude", "include")) |>
select(-n)
# join in the duplicates df
data_processed_before_exclusions <- data_processed_temp |>
full_join(data_processed_duplicates, by = "subject")
# create a master exclude_participant variable
data_processed <- data_processed_before_exclusions |>
mutate(exclude_participant = case_when(tolower(age) == "test" ~ "exclude",
tolower(gender) == "test" ~ "exclude",
is.na(mean_evaluation) ~ "exclude",
# in this case we will exclude participants with missing demographics data or outcomes measures data.
# Note that "list-wise exclusions" like this aren't always justified, as missingness often isn't at random.
# How to treat missing data is a  whole area of work in itself, which we wont cover here.
is.na(age) ~ "exclude",
is.na(gender) ~ "exclude",
exclude_amp_performance == "exclude" ~ "exclude",
exclude_duplicate_data == "exclude" ~ "exclude",
exclude_amp_completeness == "exclude" ~ "exclude",
is.na(AMP_score) ~ "exclude",
TRUE ~ "include"))
# in case this dir doesn't exist, create it
dir.create("../data/processed/")
# save data to disk in that dir
write_csv(data_processed, "../data/processed/data_processed.csv")
dir.create("../code/analysis/results") # creates a folder called 'results' in the analysis folder
dir.create("/results") # creates a folder called 'results' in the analysis folder
dir.create("results") # creates a folder called 'results'
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(tidyverse)
library(janitor) # for clean_names()
library(stringr)
# demographics
data_demographics_raw <- read_csv("../data/raw/data_demographics_raw.csv") |>
janitor::clean_names()
# data_demographics_raw_messy <- read_csv("../data/raw/data_demographics_raw_messy.csv", skip = 2) |>
#   janitor::clean_names()
# self report measure
data_selfreport_raw <- read_csv("../data/raw/data_selfreport_raw.csv") |>
janitor::clean_names()
# affect attribution procedure
data_amp_raw <- read_csv("../data/raw/data_amp_raw.csv") |>
janitor::clean_names()
dat_age_gender <- data_demographics_raw |>
select(subject, date, time, trialcode, response) |>
pivot_wider(names_from = trialcode,
values_from = response) |>
mutate(gender = tolower(gender),
gender = stringr::str_remove_all(gender, regex("\\W+")), # regex is both very useful and awful to write
gender = case_when(gender == "female" ~ gender,
gender == "male" ~ gender,
gender == "nonbinary" ~ gender,
gender == "woman" ~ "female",
gender == "man" ~ "male",
TRUE ~ "other/missing/error"),
age = case_when(str_detect(age, "^[0-9]+$") ~ age, # if the value is only numbers, keep it.
TRUE ~ "other/missing/error"))
data_amp_performance_criteria <- data_amp_raw |>
filter(blockcode != "practice",
trialcode != "instructions") |>
mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |>
group_by(subject) |>
summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))
# determine modal number of trials
data_amp_completeness <- data_amp_raw |>
filter(blockcode != "practice",
trialcode != "instructions") |>
group_by(subject) |>
count() |>
ungroup() |>
mutate(exclude_amp_completeness = ifelse(n == 72, "include", "exclude")) |>
select(-n)
# data_amp_completeness |>
#   count(n)
# trial level data
data_selfreport_trial_level <- data_selfreport_raw |>
select(subject, trialcode, response) |>
filter(trialcode %in% c("like", "prefer", "positive")) |>
rename(item = trialcode) |>
filter(response != "Ctrl+'B'") |>
mutate(response = as.numeric(response))
# mean scored
data_selfreport_mean_score <- data_selfreport_trial_level |>
group_by(subject) |>
summarize(mean_evaluation = mean(response, na.rm = TRUE))
# combined
data_selfreport_scored <-
full_join(data_selfreport_trial_level |>
pivot_wider(names_from = "item",
values_from = "response"),
data_selfreport_mean_score,
by = "subject")
# Create column with congruence score
data_amp_score_congruent <- data_amp_raw |>
select(subject, evaluative_response = correct, trialcode, blockcode) |>
filter(blockcode != "practice",
trialcode != "instructions") |>
mutate(trialcode_binary = ifelse(trialcode == "prime_positive", 1, 0),
prime_congruence = ifelse(trialcode_binary == evaluative_response, 1, 0))
# Sanity check - Part I: Check with filter if there are any wrong calculations (e.g. congruence is represented as 1 even though response and trialcode are not congruent)
data_amp_score_congruent |>
filter(evaluative_response == 0 & trialcode_binary == 1 & prime_congruence == 1) |>
nrow() == 0
data_amp_score_congruent |>
filter(evaluative_response == 1 & trialcode_binary == 0 & prime_congruence == 1) |>
nrow() == 0
data_amp_score_congruent |>
filter(evaluative_response == 1 & trialcode_binary == 1 & prime_congruence == 0) |>
nrow() == 0
data_amp_score_congruent |>
filter(evaluative_response == 0 & trialcode_binary == 0 & prime_congruence == 0) |>
nrow() == 0
# Sanity check - Part I: Also check if congruence is always either 0 or 1
data_amp_score_congruent$prime_congruence %in% c(0,1) |>
all()
# Calculate AMP score
data_amp_score <- data_amp_score_congruent |>
group_by(subject) |>
summarize(AMP_score = mean(prime_congruence, na.rm = TRUE)) |>
select(subject, AMP_score)
# Sanity check - Part II: Check if score is still numeric. Also check if score lays between 0 and 1.
is.numeric(data_amp_score$AMP_score) & data_amp_score$AMP_score |> between(0, 1) |>
all()
# combine all dfs created in the previous chunks
data_processed_temp <- dat_age_gender |>
full_join(data_selfreport_scored, by = "subject") |>
full_join(data_amp_performance_criteria, by = "subject") |>
full_join(data_amp_completeness, by = "subject") |>
full_join(data_amp_score, by = "subject")
# flag all subjects with more than one row in the wide-format data. these should be excluded in the analysis.
# a more elaborate approach would be to track down the individual duplicate cases and determine which of the multiple cases should be retained.
data_processed_duplicates <- data_processed_temp |>
count(subject) |>
mutate(exclude_duplicate_data = if_else(n > 1, "exclude", "include")) |>
select(-n)
# join in the duplicates df
data_processed_before_exclusions <- data_processed_temp |>
full_join(data_processed_duplicates, by = "subject")
# create a master exclude_participant variable
data_processed <- data_processed_before_exclusions |>
mutate(exclude_participant = case_when(tolower(age) == "test" ~ "exclude",
tolower(gender) == "test" ~ "exclude",
is.na(mean_evaluation) ~ "exclude",
# in this case we will exclude participants with missing demographics data or outcomes measures data.
# Note that "list-wise exclusions" like this aren't always justified, as missingness often isn't at random.
# How to treat missing data is a  whole area of work in itself, which we wont cover here.
is.na(age) ~ "exclude",
is.na(gender) ~ "exclude",
exclude_amp_performance == "exclude" ~ "exclude",
exclude_duplicate_data == "exclude" ~ "exclude",
exclude_amp_completeness == "exclude" ~ "exclude",
is.na(AMP_score) ~ "exclude",
TRUE ~ "include"))
# in case this dir doesn't exist, create it
dir.create("../data/processed/")
# save data to disk in that dir
write_csv(data_processed, "../data/processed/data_processed.csv")
sessionInfo()
