ggplot(aes(x = bfi_mean_c, y = d_score, group = extreme_values)) +
geom_point(aes(shape = extreme_values, color = extreme_values), alpha = 0.8) +
geom_smooth(aes(group = 1), method = "lm", fullrange = TRUE) +
scale_x_continuous(breaks = pretty_breaks(n = 6),
limits = c(1, 6)) +
scale_y_continuous(breaks = pretty_breaks(n = 8),
limits = c(-2, 2)) +
xlab("Mean Contientiousness") +
ylab("D-score") +
ggtitle("Scatter Plot: Contientiousness and D-score") +
theme_classic() +
theme(legend.position = c(0.9, 0.9)) +
guides(color = guide_legend("Outliers"),
shape = guide_legend("Outliers")) +
scale_shape_manual(values = c(17,16)) +
scale_color_manual(values = wes_palette("GrandBudapest1", n = 2, type = "continuous"))
# Scatter plot: Extroversion
plot_iat_bfi_e <- data_processed_after_exclusions |>
mutate(extreme_values = ifelse(between(d_score, quantile(d_score, 0.1), quantile(d_score, 0.9)), "Normal Values", "Extreme Values")) |>
ggplot(aes(x = bfi_mean_e, y = d_score, group = extreme_values)) +
geom_point(aes(shape = extreme_values, color = extreme_values), alpha = 0.8) +
geom_smooth(aes(group = 1), method = "lm", fullrange = TRUE) +
scale_x_continuous(breaks = pretty_breaks(n = 6),
limits = c(1, 6)) +
scale_y_continuous(breaks = pretty_breaks(n = 8),
limits = c(-2, 2)) +
xlab("Mean Extroversion") +
ylab("D-score") +
ggtitle("Scatter Plot: Extroversion and D-score") +
theme_classic() +
theme(legend.position = c(0.9, 0.9)) +
guides(color = guide_legend("Outliers"),
shape = guide_legend("Outliers")) +
scale_shape_manual(values = c(17,16)) +
scale_color_manual(values = wes_palette("GrandBudapest1", n = 2, type = "continuous"))
# Scatter plot: Neuroticism
plot_iat_bfi_n <- data_processed_after_exclusions |>
mutate(extreme_values = ifelse(between(d_score, quantile(d_score, 0.1), quantile(d_score, 0.9)), "Normal Values", "Extreme Values")) |>
ggplot(aes(x = bfi_mean_n, y = d_score, group = extreme_values)) +
geom_point(aes(shape = extreme_values, color = extreme_values), alpha = 0.8) +
geom_smooth(aes(group = 1), method = "lm", fullrange = TRUE) +
scale_x_continuous(breaks = pretty_breaks(n = 6),
limits = c(1, 6)) +
scale_y_continuous(breaks = pretty_breaks(n = 8),
limits = c(-2, 2)) +
xlab("Mean Neuroticism") +
ylab("D-score") +
ggtitle("Scatter Plot: Neuroticism and D-score") +
theme_classic() +
theme(legend.position = c(0.9, 0.9)) +
guides(color = guide_legend("Outliers"),
shape = guide_legend("Outliers")) +
scale_shape_manual(values = c(17,16)) +
scale_color_manual(values = wes_palette("GrandBudapest1", n = 2, type = "continuous"))
# Scatter plot: Openness
plot_iat_bfi_o <- data_processed_after_exclusions |>
mutate(extreme_values = ifelse(between(d_score, quantile(d_score, 0.1), quantile(d_score, 0.9)), "Normal Values", "Extreme Values")) |>
ggplot(aes(x = bfi_mean_o, y = d_score, group = extreme_values)) +
geom_point(aes(shape = extreme_values, color = extreme_values), alpha = 0.8) +
geom_smooth(aes(group = 1), method = "lm", fullrange = TRUE) +
scale_x_continuous(breaks = pretty_breaks(n = 6),
limits = c(1, 6)) +
scale_y_continuous(breaks = pretty_breaks(n = 8),
limits = c(-2, 2)) +
xlab("Mean Openness") +
ylab("D-score") +
ggtitle("Scatter Plot: Openness and D-score") +
theme_classic() +
theme(legend.position = c(0.9, 0.9)) +
guides(color = guide_legend("Outliers"),
shape = guide_legend("Outliers")) +
scale_shape_manual(values = c(17,16)) +
scale_color_manual(values = wes_palette("GrandBudapest1", n = 2, type = "continuous"))
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(tidyverse)        # for general data wrangling/tidying
library(janitor)          # for general data wrangling/tidying
library(openxlsx)         # for writing excel files (codebook)
# read in BFI data and immediately clean names
data_bfi <- read_csv("../data/raw/data_raw_bfi.csv") |>
janitor::clean_names()
# read in IAT data and immediately clean names
data_iat <- read_csv("../data/raw/data_raw_iat.csv") |>
janitor::clean_names()
# read in IAT data and immediately clean names
data_demographics <- read_csv("../data/raw/data_raw_demographics.csv") |>
janitor::clean_names()
data_demographics_clean <- data_demographics |>
drop_na(unique_id) |>
pivot_wider(names_from = "variable", values_from = "response") |>
mutate(age = ifelse(is.na(age), "missing/error/others", age),
sex = ifelse(is.na(sex), "missing/error/others", sex),
sex = recode(sex, "f" = "female", "m" = "male"),
unique_id = as.character(unique_id))
# Construct a vector of all negatively worded items
negatively_worded <- c("bfi_a1", "bfi_a3", "bfi_a6", "bfi_a8",
"bfi_c2", "bfi_c4", "bfi_c5", "bfi_c9",
"bfi_e2", "bfi_e5", "bfi_e7",
"bfi_n2", "bfi_n5", "bfi_n7",
"bfi_o7", "bfi_o9")
# Reverse negatively worded items with the vector constructed above
data_bfi_recoded <- data_bfi |>
mutate(
across(all_of(negatively_worded),
~ recode(.x, `1` = 6, `2` = 5, `3` = 4,
`4` = 3, `5` = 2, `6` = 1))
)
# Construct and print correlation matrix
data_bfi_recoded |>
select(starts_with("bfi_a")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame()
# Test for only positive values
data_bfi_recoded |>
select(starts_with("bfi_a")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame() |>
summarize(across(where(is.numeric), ~ all(. > 0))) |>
all()
# Construct and print correlation matrix
data_bfi_recoded |>
select(starts_with("bfi_c")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame()
# Test for only positive values
data_bfi_recoded |>
select(starts_with("bfi_c")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame() |>
summarize(across(where(is.numeric), ~ all(. > 0))) |>
all()
# Construct and print correlation matrix
data_bfi_recoded |>
select(starts_with("bfi_e")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame()
# Test for only positive values
data_bfi_recoded |>
select(starts_with("bfi_e")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame() |>
summarize(across(where(is.numeric), ~ all(. > 0))) |>
all()
# Construct and print correlation matrix
data_bfi_recoded |>
select(starts_with("bfi_n")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame()
# Test for only positive values
data_bfi_recoded |>
select(starts_with("bfi_n")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame() |>
summarize(across(where(is.numeric), ~ all(. > 0))) |>
all()
# Construct and print correlation matrix
data_bfi_recoded |>
select(starts_with("bfi_o")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame()
# Test for only positive values
data_bfi_recoded |>
select(starts_with("bfi_o")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame()|>
summarize(across(where(is.numeric), ~ all(. > 0))) |>
all()
# Check if there are impossible values. Participants with impossible values are first marked as "FALSE" and then as "excluded".
data_bfi_exclude_impossible_values <- data_bfi_recoded |>
mutate(exclude_impossible_values = if_all(-unique_id,
~case_when(.x < 1 ~ FALSE,
.x > 6 ~ FALSE,
TRUE ~ TRUE))) |>
mutate(across(where(is.logical), as.character)) |>
mutate(exclude_impossible_values = recode(exclude_impossible_values,
"FALSE" = "exclude", "TRUE" = "include"))
# Check for complete agreeableness subscale and calculate its mean
# Note: exclude_impossible_values is selected too because all dfs generated here will be merged in the end for the final bfi df
data_bfi_exclude_a <- data_bfi_exclude_impossible_values |>
select(unique_id:bfi_a9, exclude_impossible_values) |>
rowwise() |>
mutate(n_na_a = sum(is.na(c_across(bfi_a1:bfi_a9)))) |> # count NA values in the scale for each individual
mutate(exclusion_incomplete_scale_a = case_when(n_na_a < 1 ~ "include", # check if participants have a complete scale or did not fill out the scale at all
n_na_a > 8 ~ "include",
TRUE ~ "exclude"), # exclude the participants with an incomplete completed scale
bfi_mean_a = mean(c_across(bfi_a1:bfi_a9), na.rm = TRUE)) |> # calculate the scale mean for each individual
mutate(bfi_mean_a = ifelse(is.nan(bfi_mean_a), NA, bfi_mean_a)) |>
select(-n_na_a)
# Check for complete conscientiousness subscale and calculate its mean (see first code block of this section for more detailed comments on the working of the code)
data_bfi_exclude_c <- data_bfi_exclude_impossible_values |>
select(unique_id, bfi_c1:bfi_c9) |>
rowwise() |>
mutate(n_na_c = sum(is.na(c_across(bfi_c1:bfi_c9)))) |>
mutate(exclusion_incomplete_scale_c = case_when(n_na_c < 1 ~ "include",
n_na_c > 8 ~ "include",
TRUE ~ "exclude"),
bfi_mean_c = mean(c_across(bfi_c1:bfi_c9), na.rm = TRUE)) |>
mutate(bfi_mean_c = ifelse(is.nan(bfi_mean_c), NA, bfi_mean_c)) |>
select(-n_na_c)
# Check for complete extroversion subscale and calculate its mean (see first code block of this section for more detailed comments on the working of the code)
data_bfi_exclude_e <- data_bfi_exclude_impossible_values |>
select(unique_id, bfi_e1:bfi_e8) |>
rowwise() |>
mutate(n_na_e = sum(is.na(c_across(bfi_e1:bfi_e8)))) |>
mutate(exclusion_incomplete_scale_e = case_when(n_na_e < 1 ~ "include",
n_na_e > 7 ~ "include",
TRUE ~ "exclude"),
bfi_mean_e = mean(c_across(bfi_e1:bfi_e8), na.rm = TRUE)) |>
mutate(bfi_mean_e = ifelse(is.nan(bfi_mean_e), NA, bfi_mean_e)) |>
select(-n_na_e)
# Check for complete neuroticism subscale and calculate its mean (see first code block of this section for more detailed comments on the working of the code)
data_bfi_exclude_n <- data_bfi_exclude_impossible_values |>
select(unique_id, bfi_n1:bfi_n8) |>
rowwise() |>
mutate(n_na_n = sum(is.na(c_across(bfi_n1:bfi_n8)))) |>
mutate(exclusion_incomplete_scale_n = case_when(n_na_n < 1 ~ "include",
n_na_n > 7 ~ "include",
TRUE ~ "exclude"),
bfi_mean_n = mean(c_across(bfi_n1:bfi_n8), na.rm = TRUE)) |>
mutate(bfi_mean_n = ifelse(is.nan(bfi_mean_n), NA, bfi_mean_n)) |>
select(-n_na_n)
# Check for complete openness subscale and calculate its mean (see first code block of this section for more detailed comments on the working of the code)
data_bfi_exclude_o <- data_bfi_exclude_impossible_values |>
select(unique_id, bfi_o1, bfi_o2:bfi_o9, bfi_o10) |>
rowwise() |>
mutate(n_na_o = sum(is.na(c_across(bfi_o1:bfi_o10)))) |>
mutate(exclusion_incomplete_scale_o = case_when(n_na_o < 1 ~ "include",
n_na_o > 9 ~ "include",
TRUE ~ "exclude"),
bfi_mean_o = mean(c_across(bfi_o1:bfi_o10), na.rm = TRUE)) |>
mutate(bfi_mean_o = ifelse(is.nan(bfi_mean_o), NA, bfi_mean_o)) |>
select(-n_na_o)
# Merge all the BFI exclusions/subscale mean tables into one
data_bfi_scored <- full_join(data_bfi_exclude_a, data_bfi_exclude_c, by = "unique_id") |>
full_join(data_bfi_exclude_e, by = "unique_id") |>
full_join(data_bfi_exclude_n, by = "unique_id") |>
full_join(data_bfi_exclude_o, by = "unique_id") |>
mutate(unique_id = as.character(unique_id)) |>
select(-exclude_impossible_values, everything()) # reorder the columns (put variable exclude_impossible_values at the end)
# Sanity check for all BFI subscales (check if means are between 1 and 6)
data_bfi_scored |>
mutate(bounded_correctly = case_when(between(bfi_mean_a, left = 1, right = 6) ~ TRUE,
between(bfi_mean_c, left = 1, right = 6) ~ TRUE,
between(bfi_mean_e, left = 1, right = 6) ~ TRUE,
between(bfi_mean_n, left = 1, right = 6) ~ TRUE,
between(bfi_mean_o, left = 1, right = 6) ~ TRUE,
TRUE ~ FALSE)) |>
filter(bounded_correctly != TRUE) |> # filter out rows in which the bounds are crossed
nrow() == 0 # there should be no rows in which the bounds are crossed
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(tidyverse)        # for general data wrangling/tidying
library(janitor)          # for general data wrangling/tidying
library(openxlsx)         # for writing excel files (codebook)
# read in BFI data and immediately clean names
data_bfi <- read_csv("../data/raw/data_raw_bfi.csv") |>
janitor::clean_names()
# read in IAT data and immediately clean names
data_iat <- read_csv("../data/raw/data_raw_iat.csv") |>
janitor::clean_names()
# read in IAT data and immediately clean names
data_demographics <- read_csv("../data/raw/data_raw_demographics.csv") |>
janitor::clean_names()
data_demographics_clean <- data_demographics |>
drop_na(unique_id) |>
pivot_wider(names_from = "variable", values_from = "response") |>
mutate(age = ifelse(is.na(age), "missing/error/others", age),
sex = ifelse(is.na(sex), "missing/error/others", sex),
sex = recode(sex, "f" = "female", "m" = "male"),
unique_id = as.character(unique_id))
# Construct a vector of all negatively worded items
negatively_worded <- c("bfi_a1", "bfi_a3", "bfi_a6", "bfi_a8",
"bfi_c2", "bfi_c4", "bfi_c5", "bfi_c9",
"bfi_e2", "bfi_e5", "bfi_e7",
"bfi_n2", "bfi_n5", "bfi_n7",
"bfi_o7", "bfi_o9")
# Reverse negatively worded items with the vector constructed above
data_bfi_recoded <- data_bfi |>
mutate(
across(all_of(negatively_worded),
~ recode(.x, `1` = 6, `2` = 5, `3` = 4,
`4` = 3, `5` = 2, `6` = 1))
)
# Construct and print correlation matrix
data_bfi_recoded |>
select(starts_with("bfi_a")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame()
# Test for only positive values
data_bfi_recoded |>
select(starts_with("bfi_a")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame() |>
summarize(across(where(is.numeric), ~ all(. > 0))) |>
all()
# Construct and print correlation matrix
data_bfi_recoded |>
select(starts_with("bfi_c")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame()
# Test for only positive values
data_bfi_recoded |>
select(starts_with("bfi_c")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame() |>
summarize(across(where(is.numeric), ~ all(. > 0))) |>
all()
# Construct and print correlation matrix
data_bfi_recoded |>
select(starts_with("bfi_e")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame()
# Test for only positive values
data_bfi_recoded |>
select(starts_with("bfi_e")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame() |>
summarize(across(where(is.numeric), ~ all(. > 0))) |>
all()
# Construct and print correlation matrix
data_bfi_recoded |>
select(starts_with("bfi_n")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame()
# Test for only positive values
data_bfi_recoded |>
select(starts_with("bfi_n")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame() |>
summarize(across(where(is.numeric), ~ all(. > 0))) |>
all()
# Construct and print correlation matrix
data_bfi_recoded |>
select(starts_with("bfi_o")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame()
# Test for only positive values
data_bfi_recoded |>
select(starts_with("bfi_o")) |>
cor(use = "pairwise.complete.obs") |>
as.data.frame()|>
summarize(across(where(is.numeric), ~ all(. > 0))) |>
all()
# Check if there are impossible values. Participants with impossible values are first marked as "FALSE" and then as "excluded".
data_bfi_exclude_impossible_values <- data_bfi_recoded |>
mutate(exclude_impossible_values = if_all(-unique_id,
~case_when(.x < 1 ~ FALSE,
.x > 6 ~ FALSE,
TRUE ~ TRUE))) |>
mutate(across(where(is.logical), as.character)) |>
mutate(exclude_impossible_values = recode(exclude_impossible_values,
"FALSE" = "exclude", "TRUE" = "include"))
# Check for complete agreeableness subscale and calculate its mean
# Note: exclude_impossible_values is selected too because all dfs generated here will be merged in the end for the final bfi df
data_bfi_exclude_a <- data_bfi_exclude_impossible_values |>
select(unique_id:bfi_a9, exclude_impossible_values) |>
rowwise() |>
mutate(n_na_a = sum(is.na(c_across(bfi_a1:bfi_a9)))) |> # count NA values in the scale for each individual
mutate(exclusion_incomplete_scale_a = case_when(n_na_a < 1 ~ "include", # check if participants have a complete scale or did not fill out the scale at all
n_na_a > 8 ~ "include",
TRUE ~ "exclude"), # exclude the participants with an incomplete completed scale
bfi_mean_a = mean(c_across(bfi_a1:bfi_a9), na.rm = TRUE)) |> # calculate the scale mean for each individual
mutate(bfi_mean_a = ifelse(is.nan(bfi_mean_a), NA, bfi_mean_a)) |>
select(-n_na_a)
# Check for complete conscientiousness subscale and calculate its mean (see first code block of this section for more detailed comments on the working of the code)
data_bfi_exclude_c <- data_bfi_exclude_impossible_values |>
select(unique_id, bfi_c1:bfi_c9) |>
rowwise() |>
mutate(n_na_c = sum(is.na(c_across(bfi_c1:bfi_c9)))) |>
mutate(exclusion_incomplete_scale_c = case_when(n_na_c < 1 ~ "include",
n_na_c > 8 ~ "include",
TRUE ~ "exclude"),
bfi_mean_c = mean(c_across(bfi_c1:bfi_c9), na.rm = TRUE)) |>
mutate(bfi_mean_c = ifelse(is.nan(bfi_mean_c), NA, bfi_mean_c)) |>
select(-n_na_c)
# Check for complete extroversion subscale and calculate its mean (see first code block of this section for more detailed comments on the working of the code)
data_bfi_exclude_e <- data_bfi_exclude_impossible_values |>
select(unique_id, bfi_e1:bfi_e8) |>
rowwise() |>
mutate(n_na_e = sum(is.na(c_across(bfi_e1:bfi_e8)))) |>
mutate(exclusion_incomplete_scale_e = case_when(n_na_e < 1 ~ "include",
n_na_e > 7 ~ "include",
TRUE ~ "exclude"),
bfi_mean_e = mean(c_across(bfi_e1:bfi_e8), na.rm = TRUE)) |>
mutate(bfi_mean_e = ifelse(is.nan(bfi_mean_e), NA, bfi_mean_e)) |>
select(-n_na_e)
# Check for complete neuroticism subscale and calculate its mean (see first code block of this section for more detailed comments on the working of the code)
data_bfi_exclude_n <- data_bfi_exclude_impossible_values |>
select(unique_id, bfi_n1:bfi_n8) |>
rowwise() |>
mutate(n_na_n = sum(is.na(c_across(bfi_n1:bfi_n8)))) |>
mutate(exclusion_incomplete_scale_n = case_when(n_na_n < 1 ~ "include",
n_na_n > 7 ~ "include",
TRUE ~ "exclude"),
bfi_mean_n = mean(c_across(bfi_n1:bfi_n8), na.rm = TRUE)) |>
mutate(bfi_mean_n = ifelse(is.nan(bfi_mean_n), NA, bfi_mean_n)) |>
select(-n_na_n)
# Check for complete openness subscale and calculate its mean (see first code block of this section for more detailed comments on the working of the code)
data_bfi_exclude_o <- data_bfi_exclude_impossible_values |>
select(unique_id, bfi_o1, bfi_o2:bfi_o9, bfi_o10) |>
rowwise() |>
mutate(n_na_o = sum(is.na(c_across(bfi_o1:bfi_o10)))) |>
mutate(exclusion_incomplete_scale_o = case_when(n_na_o < 1 ~ "include",
n_na_o > 9 ~ "include",
TRUE ~ "exclude"),
bfi_mean_o = mean(c_across(bfi_o1:bfi_o10), na.rm = TRUE)) |>
mutate(bfi_mean_o = ifelse(is.nan(bfi_mean_o), NA, bfi_mean_o)) |>
select(-n_na_o)
# Merge all the BFI exclusions/subscale mean tables into one
data_bfi_scored <- full_join(data_bfi_exclude_a, data_bfi_exclude_c, by = "unique_id") |>
full_join(data_bfi_exclude_e, by = "unique_id") |>
full_join(data_bfi_exclude_n, by = "unique_id") |>
full_join(data_bfi_exclude_o, by = "unique_id") |>
mutate(unique_id = as.character(unique_id)) |>
select(-exclude_impossible_values, everything()) # reorder the columns (put variable exclude_impossible_values at the end)
# Sanity check for all BFI subscales (check if means are between 1 and 6)
data_bfi_scored |>
mutate(bounded_correctly = case_when(between(bfi_mean_a, left = 1, right = 6) ~ TRUE,
between(bfi_mean_c, left = 1, right = 6) ~ TRUE,
between(bfi_mean_e, left = 1, right = 6) ~ TRUE,
between(bfi_mean_n, left = 1, right = 6) ~ TRUE,
between(bfi_mean_o, left = 1, right = 6) ~ TRUE,
TRUE ~ FALSE)) |>
filter(bounded_correctly != TRUE) |> # filter out rows in which the bounds are crossed
nrow() == 0 # there should be no rows in which the bounds are crossed
View(data_iat)
# Some data wrangling/tidying for the IAT data (change header names, clean/rename header names, select relevant columns and rows)
data_iat_clean <- data_iat |>
janitor::row_to_names(row_number = 1) |>
janitor::clean_names() |>
rename(trial_rt = trial_reaction_time_in_ms) |>
select(unique_id, block_number, trial_accuracy, trial_rt) |>
mutate(trial_rt = as.numeric(trial_rt)) |>
filter(!block_number %in% c(1,2,5)) # only keep the critical blocks (3, 4, 6, 7)
View(data_iat_clean)
data_iat_clean <- data_iat |>
janitor::row_to_names(row_number = 1) |>
janitor::clean_names()
View(data_iat_clean)
data_iat_mean1 <- data_iat_clean |>
filter(block_number %in% c(3, 6))
View(data_iat_mean1)
data_iat_mean1 <- data_iat_clean |>
filter(block_number %in% c(3, 6)) |>
group_by(unique_id) |>
summarize(mean1 = mean(trial_rt, na.rm = TRUE))
# Some data wrangling/tidying for the IAT data (change header names, clean/rename header names, select relevant columns and rows)
data_iat_clean <- data_iat |>
janitor::row_to_names(row_number = 1) |>
janitor::clean_names() |>
rename(trial_rt = trial_reaction_time_in_ms) |>
select(unique_id, block_number, trial_accuracy, trial_rt) |>
mutate(trial_rt = as.numeric(trial_rt)) |>
filter(!block_number %in% c(1,2,5)) # only keep the critical blocks (3, 4, 6, 7)
data_iat_mean1 <- data_iat_clean |>
filter(block_number %in% c(3, 6)) |>
group_by(unique_id) |>
summarize(mean1 = mean(trial_rt, na.rm = TRUE))
View(data_iat_mean1)
data_iat_mean1 <- data_iat_clean |>
filter(block_number %in% c(3, 6))
View(data_iat_mean1)
data_iat_mean2 <- data_iat_clean |>
filter(block_number %in% c(4, 7))
View(data_iat_mean2)
# Calculate mean2 (mean of block 4 and 7)
data_iat_mean2 <- data_iat_clean |>
filter(block_number %in% c(4, 7)) |>
group_by(unique_id) |>
summarize(mean2 = mean(trial_rt, na.rm = TRUE))
# Calculate mean1 (mean of block 3 and 6)
data_iat_mean1 <- data_iat_clean |>
filter(block_number %in% c(3, 6)) |>
group_by(unique_id) |>
summarize(mean1 = mean(trial_rt, na.rm = TRUE))
View(data_iat_mean2)
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(tidyverse)        # for general data wrangling/tidying
library(janitor)          # for general data wrangling/tidying
library(openxlsx)         # for writing excel files (codebook)
# read in BFI data and immediately clean names
data_bfi <- read_csv("../data/raw/data_raw_bfi.csv") |>
janitor::clean_names()
# read in IAT data and immediately clean names
data_iat <- read_csv("../data/raw/data_raw_iat.csv") |>
janitor::clean_names()
# read in IAT data and immediately clean names
data_demographics <- read_csv("../data/raw/data_raw_demographics.csv") |>
janitor::clean_names()
data_demographics_clean <- data_demographics |>
drop_na(unique_id) |>
pivot_wider(names_from = "variable", values_from = "response") |>
mutate(age = ifelse(is.na(age), "missing/error/others", age),
sex = ifelse(is.na(sex), "missing/error/others", sex),
sex = recode(sex, "f" = "female", "m" = "male"),
unique_id = as.character(unique_id))
View(data_bfi)
# Construct a vector of all negatively worded items
negatively_worded <- c("bfi_a1", "bfi_a3", "bfi_a6", "bfi_a8",
"bfi_c2", "bfi_c4", "bfi_c5", "bfi_c9",
"bfi_e2", "bfi_e5", "bfi_e7",
"bfi_n2", "bfi_n5", "bfi_n7",
"bfi_o7", "bfi_o9")
# Reverse negatively worded items with the vector constructed above
data_bfi_recoded <- data_bfi |>
mutate(
across(all_of(negatively_worded),
~ recode(.x, `1` = 6, `2` = 5, `3` = 4,
`4` = 3, `5` = 2, `6` = 1))
)
View(data_bfi_recoded)
